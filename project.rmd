---
title: "PML Project"
author: "andromisnati"
date: "Saturday, March 14, 2015"
output: html_document
---

##Executive Summary

In this report we'll develop an algorithm to classify the way an exercise is made by using accelerometer variables as predictors. We develop two models: one based in knn and other using random forests (both models use a PCA preProcess). The accuracies are 96% and 98% respectively, with the second one being more computationally consuming.

### Reading data and loading libraries

First we'll read the test and training data. We have to make a validation partition from the training data.

```{r, message=FALSE, warning=FALSE}
library(caret)
traindata<-read.csv("pml-training.csv")
inTrain <- createDataPartition( traindata$classe, p=0.7, list=FALSE);
training <- traindata[ inTrain,];
validation <- traindata[ -inTrain,];
testdata<-read.csv("pml-testing.csv")
```

Now, we'll look at the data we have read.  As we don't know how many predictors we have, we'll first make a count of columns.

```{r}
length(names(traindata))
```

We notice a high number of predictors, so we could use a way to reduce them.  

### Cleaning data

An out-of-the-hat way is to remove all the columns that have NAs and blank strings.

```{r, cache=TRUE}
training2 <- training[,  !apply( is.na(training), 2,any)]
training2 <- training2[, !apply( training2=="",   2,any)]
length(names(training2))
```

### Models creation & Accuracy

We have now 60 predictors, so we'll try to use them to fit a model. We'll start using the knn method, to determine the closest neighbors of the each prediction classes.  We'll make a preprocessing with pca.

```{r, cache=TRUE}
model1<-train(classe~.,data=training2, method = "knn",preProcess="pca")
```

We'll now use our model to predict the classes of our test data, to calculate de sample error.

```{r, cache=TRUE}
confusionMatrix( predict( model1, validation ), validation$classe );
```

We notice an accuracy that goes between 96~98% in each class (overall ~96%).  We'll try another method to see if we can improve it.  We'll now use a bagging method, Random Forest. We have to keep in mind that this method will be very time-consuming.

```{r, cache=TRUE, warning=FALSE }
model2<-train(classe~.,data=training2, method = "rf",preProcess="pca")
```
We'll evaluate our model in the same way we did in our previous model.

```{r, cache=TRUE, warning=FALSE}
confusionMatrix( predict( model2, validation ), validation$classe );
```

We notice the accuracy has improved to 98%.  We'll use this model to pass the test data, but we should take notice that for only a 2% more of accuracy, a lot of computational power and time (hour and a half) was required.  In a real life situation, this decision may not be possible.

```{r, echo=FALSE,  warning=FALSE}
pml_write_files = function(x){
     n = length(x)
     for(i in 1:n){
         filename = paste0("problem_id_",i,".txt")
         write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
     }
 }
answers<-predict( model2, testdata)
```